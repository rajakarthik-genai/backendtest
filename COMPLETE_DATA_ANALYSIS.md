# 🔍 Complete Analysis: How MediTwin API Data is Generated

## 📌 Executive Summary

**Key Finding**: The anatomy API endpoints return data that is **NOT generated by LLMs**. Instead, the system uses:
- **Rule-based algorithms** for severity calculations
- **Database queries** for historical data
- **Graph traversal** for relationships
- **Mathematical aggregation** for statistics

**LLMs are only used for expert medical opinions when specifically requested by users.**

## 🏗️ Data Generation Architecture

### 1. Document Processing Pipeline
```
Document → Text Extraction → Entity Recognition → Neo4j Storage → Severity Calculation → API Response
```

### 2. Core Components

| Component | File | Method | LLM Used? |
|-----------|------|--------|-----------|
| **Text Extraction** | `src/agents/ingestion_agent.py` | PDF/OCR processing | ❌ No |
| **Entity Recognition** | `src/agents/ingestion_agent.py` | **LLM structured output** | ✅ Yes (NEW) |
| **Severity Calculation** | `src/db/neo4j_db.py` | Rule-based algorithm | ❌ No |
| **API Data Assembly** | `src/api/endpoints/anatomy.py` | Database queries | ❌ No |
| **Expert Opinions** | `src/agents/*_agent.py` | Medical reasoning | ✅ Yes |

## 📊 API Endpoint Data Generation

### 1. GET /anatomy/body-parts

**Purpose**: Returns severity status for all 30 body parts (for 3D visualization)

**Data Generation Process**:
```python
@router.get("/body-parts")
async def get_body_parts_severities(current_user: CurrentUser):
    # Step 1: Get user ID from JWT token
    user_id = current_user.user_id
    
    # Step 2: Ensure user graph exists (auto-create if needed)
    neo4j_client = get_graph()
    neo4j_client.ensure_user_initialized(user_id)
    
    # Step 3: Query Neo4j for RULE-BASED severity data
    severities = neo4j_client.get_body_part_severities(user_id)
    
    # Step 4: Format for frontend
    body_parts_data = []
    for body_part, severity in severities.items():
        body_parts_data.append({
            "name": body_part,
            "severity": severity  # CALCULATED, not LLM-generated
        })
    
    return {
        "user_id": user_id,
        "body_parts": body_parts_data,
        "total_parts": len(body_parts_data)
    }
```

**Sample Response**:
```json
{
  "user_id": "user123",
  "body_parts": [
    {"name": "Heart", "severity": "mild"},
    {"name": "Left Lung", "severity": "normal"},
    {"name": "Liver", "severity": "moderate"},
    {"name": "Brain", "severity": "NA"}
  ],
  "total_parts": 30
}
```

### 2. GET /anatomy/body-part/{body_part}

**Purpose**: Returns detailed information for a specific body part

**Data Generation Process**:
```python
@router.get("/body-part/{body_part}")
async def get_body_part_details(current_user: CurrentUser, body_part: str):
    # Step 1: Get current severity (RULE-BASED CALCULATION)
    severities = neo4j_client.get_body_part_severities(user_id)
    current_severity = severities.get(body_part, "NA")
    
    # Step 2: Get event history (DATABASE QUERY)
    event_history = neo4j_client.get_body_part_history(user_id, body_part)
    
    # Step 3: Get related conditions (GRAPH TRAVERSAL)
    related_conditions = neo4j_client.get_related_conditions(user_id, recent_event.get("title", ""))
    
    # Step 4: Calculate statistics (MATHEMATICAL AGGREGATION)
    total_events = len(event_history)
    severity_counts = {}
    for event in event_history:
        sev = event.get("severity", "unknown")
        severity_counts[sev] = severity_counts.get(sev, 0) + 1
    
    return {
        "body_part": body_part,
        "current_severity": current_severity,  # RULE-BASED
        "statistics": {
            "total_events": total_events,      # COUNT
            "severity_distribution": severity_counts  # AGGREGATION
        },
        "recent_events": event_history[:10],   # DATABASE QUERY
        "related_conditions": related_conditions[:5]  # GRAPH TRAVERSAL
    }
```

## 🔧 Severity Calculation Algorithm

**File**: `src/db/neo4j_db.py` - `calculate_severity_from_events()` method

**Step-by-Step Process**:

### 1. Data Collection
```python
# Query Neo4j for events affecting this body part in last 90 days
query = """
MATCH (p:Patient {patient_id: $patient_id})-[:HAS_EVENT]->(e:Event)-[:AFFECTS]->(b:BodyPart {name: $body_part})
WHERE e.timestamp >= datetime() - duration({days: 90})
RETURN e.severity as event_severity, 
       e.event_type as event_type,
       e.confidence as confidence,
       count(e) as event_count
ORDER BY e.timestamp DESC
"""
```

### 2. Severity Scoring
```python
# Rule-based severity calculation
severity_scores = {
    "critical": 10,
    "severe": 8,
    "moderate": 6,
    "mild": 4,
    "normal": 2,
    "NA": 0
}

# Count events by severity
critical_count = 0
severe_count = 0
moderate_count = 0
total_score = 0
total_events = 0

for record in result:
    event_severity = record["event_severity"]
    confidence = record.get("confidence", 1.0)
    
    score = severity_scores.get(event_severity, 0)
    weighted_score = score * confidence
    total_score += weighted_score
    total_events += 1
    
    if event_severity == "critical":
        critical_count += 1
    elif event_severity == "severe":
        severe_count += 1
    elif event_severity == "moderate":
        moderate_count += 1
```

### 3. Final Severity Determination
```python
# Apply business rules
if total_events == 0:
    return "NA"

average_score = total_score / total_events

# Determine overall severity with enhanced logic
if critical_count > 0 or average_score >= 8:
    return "critical"
elif severe_count > 0 or average_score >= 6:
    return "severe"
elif moderate_count > 1 or average_score >= 4:
    return "moderate"
elif total_events > 3 or average_score >= 2:
    return "mild"
elif total_events > 0:
    return "normal"
else:
    return "NA"
```

## 🤖 LLM Agent Usage (For Expert Opinions Only)

### When LLMs Are Used

LLMs are **only** used when:
1. User asks for medical opinions: "What does this pain in my chest mean?"
2. Expert consultation is requested: "I need a cardiologist's opinion"
3. Medical reasoning is required: "Explain my symptoms"

### Agent Architecture

```
User Query → Orchestrator → Specialist Agent → Tools → LLM → Expert Opinion
```

### 1. Orchestrator Agent
**File**: `src/agents/orchestrator_agent.py`
**Prompt**: `src/prompts/orchestrator_prompt.json`

**Key Responsibilities**:
- Route queries to appropriate specialists
- Coordinate multiple specialist responses
- Aggregate medical opinions

**Prompt Structure**:
```json
{
  "agent": "Orchestrator Agent",
  "role": "Central coordinator that decides which specialist agents to invoke",
  "goals": [
    "Analyse every incoming user query and decide whether it concerns the heart, brain, musculoskeletal system, or is general.",
    "Call only the relevant specialist agent functions using OpenAI function-calling.",
    "Never answer a medical question directly unless trivially obvious"
  ],
  "available_functions": {
    "cardiologist": "cardiologist(query:str)",
    "neurologist": "neurologist(query:str)",
    "orthopedist": "orthopedist(query:str)",
    "general_physician": "general_physician(query:str)",
    "aggregator": "aggregator(answers:list[str])"
  }
}
```

### 2. Specialist Agents
**Files**: `src/agents/cardiologist_agent.py`, `src/agents/neurologist_agent.py`, etc.
**Base Class**: `src/agents/base_specialist.py`

**Cardiologist Agent Prompt** (`src/prompts/cardiologist_prompt.json`):
```json
{
  "agent": "Cardiologist Agent",
  "role": "Heart & circulatory system expert.",
  "goals": [
    "Interpret cardiovascular symptoms and patient heart-related data accurately.",
    "Explain heart findings in clear, patient-friendly language.",
    "Request extra tests only when truly necessary."
  ],
  "data_sources_via_tools": {
    "web_search.search": "latest research / guideline references",
    "vector_store.query_text": "embedded cardiology papers / protocols",
    "knowledge_graph.query_natural": "relations (symptom ↔ disease ↔ treatment)",
    "document_db.get_patient_profile": "basic profile for risk stratification",
    "document_db.get_patient_record": "lab ECG echo cholesterol etc."
  },
  "step_by_step_reasoning": [
    "1️⃣ Read patient's query and any provided vitals/history.",
    "2️⃣ Decide if current knowledge suffices. If not, pick the most cost-effective tool:",
    "   • For guideline thresholds → vector_store",
    "   • For up-to-date trial info → web_search",
    "   • For patient lab numbers → document_db",
    "   • For pathophysiology links → knowledge_graph"
  ]
}
```

### 3. Tool Usage by Specialists

**File**: `src/agents/base_specialist.py` - `_knowledge_graph_query()` method

**How LLMs Get Body Part Data**:
```python
async def _knowledge_graph_query(self, query: str, user_id: str) -> str:
    """Query the knowledge graph for patient information."""
    
    graph_db = get_graph()
    graph_db.ensure_user_initialized(user_id)
    
    # Get body part severities (RULE-BASED CALCULATION)
    severities = graph_db.get_body_part_severities(user_id)
    
    # Get recent events for context (DATABASE QUERY)
    timeline = graph_db.get_patient_timeline(user_id, limit=10)
    
    # Build context response
    context = {
        "body_part_severities": severities,  # RULE-BASED DATA
        "recent_events": timeline,           # DATABASE QUERY
        "query_processed": True
    }
    
    return json.dumps(context)  # This goes to the LLM as context
```

**Available Tools for LLMs**:
```python
tools_schema = [
    {
        "type": "function",
        "function": {
            "name": "query_knowledge_graph",
            "description": "Query the patient's medical knowledge graph for related conditions and events."
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "Search the web for current medical guidance and research."
        }
    },
    {
        "type": "function",
        "function": {
            "name": "query_vector_db",
            "description": "Semantic similarity search in the medical knowledge vector database."
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_patient_records",
            "description": "Retrieve specific patient medical records by type."
        }
    }
]
```

## 🎯 Entity Extraction Process

**File**: `src/agents/ingestion_agent.py` - `_extract_medical_entities()` method

**NEW: LLM-Powered Implementation**:
```python
async def _extract_medical_entities(self, text: str) -> List[Dict[str, Any]]:
    """Extract medical entities from text using LLM-powered structured extraction."""
    
    # Use OpenAI's structured output with JSON schema
    extraction_schema = {
        "type": "object",
        "properties": {
            "medical_events": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "body_part": {"type": "string", "enum": body_parts},
                        "condition": {"type": "string"},
                        "severity": {"type": "string", "enum": ["critical", "severe", "moderate", "mild", "normal"]},
                        "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0}
                    }
                }
            }
        }
    }
    
    # Call OpenAI with structured output
    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": medical_extraction_prompt},
            {"role": "user", "content": text}
        ],
        response_format={
            "type": "json_schema",
            "json_schema": {"schema": extraction_schema, "strict": True}
        }
    )
    
    # Parse structured JSON response
    result = json.loads(response.choices[0].message.content)
    return result["medical_events"]
```

**Fallback Implementation** (when LLM fails):
```python
async def _fallback_keyword_extraction(self, text: str) -> List[Dict[str, Any]]:
    """Fallback keyword-based extraction if LLM fails."""
    
    medical_keywords = {
        "conditions": ["diabetes", "hypertension", "asthma", "pneumonia", "covid", "cancer"],
        "medications": ["metformin", "lisinopril", "albuterol", "aspirin", "insulin"],
        "body_parts": ["heart", "lung", "liver", "kidney", "brain", "arm", "leg"],
        "symptoms": ["pain", "fever", "cough", "fatigue", "nausea", "headache"]
    }
    
    # Keyword matching with lower confidence
    entities = []
    for category, keywords in medical_keywords.items():
        for keyword in keywords:
            if keyword in text.lower():
                entities.append({
                    "type": category,
                    "text": keyword,
                    "confidence": 0.6,  # Lower confidence for fallback
                    "extraction_method": "keyword_matching_fallback"
                })
    
    return entities
```

## 📋 Data Sources Summary

### API Data (Hybrid: LLM + Rule-Based)
| Data Type | Source | Method |
|-----------|--------|--------|
| **Medical Entity Extraction** | `ingestion_agent.py` | **LLM structured output (NEW)** |
| **Body Part Severities** | `neo4j_db.py` | Rule-based calculation |
| **Event History** | `neo4j_db.py` | Database query |
| **Related Conditions** | `neo4j_db.py` | Graph traversal |
| **Statistics** | `api/endpoints/anatomy.py` | Mathematical aggregation |
| **Body Part List** | `config/body_parts.py` | Static configuration |

### LLM-Generated Data (Enhanced Usage)
| Data Type | Source | Method |
|-----------|--------|--------|
| **Medical Entity Recognition** | Ingestion agent | **LLM structured JSON extraction** |
| **Medical Explanations** | Specialist agents | LLM reasoning |
| **Recommendations** | Specialist agents | LLM + retrieved data |
| **Differential Diagnoses** | Specialist agents | Medical AI reasoning |
| **Treatment Suggestions** | Specialist agents | Professional AI advice |

## 🔍 Key Configuration Files

### 1. Body Parts Configuration
**File**: `src/config/body_parts.py`
- Defines exactly 30 body parts for 3D visualization
- Provides keyword mapping for text extraction
- Includes severity levels and validation functions

### 2. Agent Prompts
**Directory**: `src/prompts/`
- `orchestrator_prompt.json` - Routing and coordination
- `cardiologist_prompt.json` - Heart specialist
- `neurologist_prompt.json` - Brain specialist
- `orthopedist_prompt.json` - Bone/joint specialist
- `general_physician_prompt.json` - General medical advice

### 3. API Endpoints
**File**: `src/api/endpoints/anatomy.py`
- `/anatomy/body-parts` - All body parts with severities
- `/anatomy/body-part/{name}` - Detailed body part information
- `/anatomy/body-part/{name}/severity` - Manual severity update
- `/anatomy/auto-update-severities` - Recalculate all severities

## 🎯 Conclusion

The MediTwin system uses a **sophisticated hybrid architecture**:

### ✅ **Rule-Based Components** (Fast, Accurate, Explainable)
- Severity calculations using mathematical algorithms
- Entity extraction using keyword matching
- Database queries for historical data
- Graph traversal for relationships

### ✅ **LLM Components** (Expert Medical Reasoning)
- Medical opinion generation by specialist agents
- Natural language understanding for user queries
- Professional medical advice and recommendations
- Complex medical reasoning and explanations

### ✅ **Key Benefits**
- **Performance**: Fast API responses for 3D visualization
- **Accuracy**: Consistent, rule-based severity calculations
- **Explainability**: Clear algorithms for data generation
- **Medical Expertise**: Professional AI opinions when needed
- **Reliability**: No hallucination in numerical data
- **Scalability**: Efficient database operations

**The system ensures that critical medical data (severities, statistics, events) are generated through reliable, rule-based methods, while leveraging LLM capabilities for expert medical opinions and natural language interactions.**
